{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da36b473",
   "metadata": {},
   "source": [
    "# üï∏Ô∏è Advanced Web Scraping Project ‚Äì IBM Data Analyst Capstone\n",
    "\n",
    "This project explores deeper web scraping skills:\n",
    "- Scraping programming language popularity data\n",
    "- Parsing structured HTML tables\n",
    "- Cleaning, analyzing, and saving scraped data\n",
    "- Visualizing top programming languages\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75196c9f",
   "metadata": {},
   "source": [
    "# üï∏Ô∏è Web Scraping Project ‚Äì IBM Data Analyst Capstone\n",
    "\n",
    "This project demonstrates how to:\n",
    "- Download webpages\n",
    "- Scrape hyperlinks and images\n",
    "- Extract tabular data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcca9be",
   "metadata": {},
   "source": [
    "# **Case Study: Web Scraping**\n",
    "\n",
    "# Objectives\n",
    "After completing this hands-on lab work, we will be able to:\n",
    "\n",
    "<ul>\n",
    "<li>Extract information from a given web site.</li>\n",
    "<li>Write the scraped data into a csv file.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3ab3b",
   "metadata": {},
   "source": [
    "## Extract information from the given web site\n",
    "You will extract the data from the below web site: <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fff55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this url contains the data you need to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372768e",
   "metadata": {},
   "source": [
    "The data you need to scrape is the **name of the programming language** and **average annual salary**.<br> It is a good idea to open the url in your web broswer and study the contents of the web page before you start to scrape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33fd08f",
   "metadata": {},
   "source": [
    "Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af074f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a webpage\n",
    "import pandas as pd\n",
    "\n",
    "print(soup.prettify()[:500])  # Preview first 500 characters of parsed HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2571f68",
   "metadata": {},
   "source": [
    "Download the webpage at the url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fc504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data  = requests.get(url)\n",
    "data = data.text\n",
    "\n",
    "print(response.status_code)  # Confirm successful download (200 OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9dbf44",
   "metadata": {},
   "source": [
    "Create a soup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b37a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html.parser\")  # create a soup object using the variable 'data'\n",
    "\n",
    "print(soup.prettify()[:500])  # Preview first 500 characters of parsed HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b0c4f",
   "metadata": {},
   "source": [
    "Scrape the `Language name` and `annual average salary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a'): # in html anchor/link is represented by the tag <a>\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a html table in the web page\n",
    "table = soup.find('table') # in html table is represented by the tag <table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa5414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column headers (Handle cases where headers are missing `<th>`)\n",
    "headers = []\n",
    "header_row = table.find(\"tr\")  # Find the first row (headers may be inside <td>)\n",
    "if header_row:\n",
    "    headers = [header.text.strip() for header in header_row.find_all([\"th\", \"td\"])]  # Search for both <th> and <td>\n",
    "\n",
    "# Extract table rows\n",
    "rows = []\n",
    "for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cols = row.find_all(\"td\")\n",
    "    cols = [col.text.strip() for col in cols]\n",
    "    rows.append(cols)\n",
    "\n",
    "# Ensure headers exist, otherwise create default headers\n",
    "if not headers:\n",
    "    headers = [f\"Column_{i}\" for i in range(len(rows[0]))]  # Create generic column names if none found\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df_languages = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "print(f\"Number of tables found: {len(tables)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0ddc2",
   "metadata": {},
   "source": [
    "Save the scrapped data into a file named *popular-languages.csv*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92639b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scraped data into a CSV file\n",
    "csv_filename = \"popular-languages.csv\"\n",
    "df_languages.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Display the extracted data\n",
    "print(f\"Popular Programming Languages {df_languages}.\")\n",
    "\n",
    "print(f\"Scraped data successfully saved in {csv_filename}.\")\n",
    "\n",
    "\n",
    "print('Data exported successfully as CSV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d999b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d57ce0ee",
   "metadata": {},
   "source": [
    "<strong>FULL CODE SCRIPT BELOW</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL containing the data to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "\n",
    "# Get the webpage content\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "# Extract the table data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Extract column headers (Handle cases where headers are missing `<th>`)\n",
    "headers = []\n",
    "header_row = table.find(\"tr\")  # Find the first row (headers may be inside <td>)\n",
    "if header_row:\n",
    "    headers = [header.text.strip() for header in header_row.find_all([\"th\", \"td\"])]  # Search for both <th> and <td>\n",
    "\n",
    "# Extract table rows\n",
    "rows = []\n",
    "for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cols = row.find_all(\"td\")\n",
    "    cols = [col.text.strip() for col in cols]\n",
    "    rows.append(cols)\n",
    "\n",
    "# Ensure headers exist, otherwise create default headers\n",
    "if not headers:\n",
    "    headers = [f\"Column_{i}\" for i in range(len(rows[0]))]  # Create generic column names if none found\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df_languages = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Save the scraped data into a CSV file\n",
    "csv_filename = \"popular-languages.csv\"\n",
    "df_languages.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Display the extracted data\n",
    "# import ace_tools as tools\n",
    "# tools.display_dataframe_to_user(name=\"Popular Programming Languages\", dataframe=df_languages)\n",
    "print(f\"Popular Programming Languages {df_languages}.\")\n",
    "\n",
    "print(f\"Scraped data successfully saved in {csv_filename}.\")\n",
    "\n",
    "\n",
    "print(soup.prettify()[:500])  # Preview first 500 characters of parsed HTML\n",
    "\n",
    "print(f\"Number of tables found: {len(tables)}\")\n",
    "\n",
    "print('Data exported successfully as CSV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a4e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788cda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# STEP 1: URL to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "# STEP 2: Scrape and parse HTML\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# STEP 3: Extract headers and rows\n",
    "headers = [th.text.strip() for th in table.find(\"tr\").find_all([\"th\", \"td\"])]\n",
    "rows = []\n",
    "for tr in table.find_all(\"tr\")[1:]:\n",
    "    cols = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "    rows.append(cols)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# STEP 4: Clean salary column\n",
    "df[\"Average Annual Salary\"] = df[\"Average Annual Salary\"].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# STEP 5: Sort data\n",
    "df_sorted = df.sort_values(by=\"Average Annual Salary\", ascending=False)\n",
    "\n",
    "# STEP 6: Create chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = plt.cm.plasma(np.linspace(0, 1, len(df_sorted)))\n",
    "bars = plt.bar(df_sorted[\"Language\"], df_sorted[\"Average Annual Salary\"], color=colors)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + 2000, f\"${int(height):,}\",\n",
    "             ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.title(\"Popular Programming Languages by Average Annual Salary\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"Programming Language\")\n",
    "plt.ylabel(\"Average Annual Salary (USD)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# STEP 7: Save chart\n",
    "plt.savefig(\"popular_languages_salary_chart.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(soup.prettify()[:500])  # Preview first 500 characters of parsed HTML\n",
    "\n",
    "print(f\"Number of tables found: {len(tables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33874beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93902a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    \"Language\": [\"Python\", \"Java\", \"R\", \"Javascript\", \"Swift\", \"C++\", \"C#\", \"PHP\", \"SQL\", \"Go\"],\n",
    "    \"Created By\": [\n",
    "        \"Guido van Rossum\", \"James Gosling\", \"Robert Gentleman, Ross Ihaka\", \"Netscape\",\n",
    "        \"Apple\", \"Bjarne Stroustrup\", \"Microsoft\", \"Rasmus Lerdorf\",\n",
    "        \"Donald D. Chamberlin, Raymond F. Boyce.\", \"Robert Griesemer, Ken Thompson, Rob Pike.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Placeholder bar height\n",
    "bar_height = np.ones(len(df)) * 1\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(df)))\n",
    "bars = plt.bar(df[\"Language\"], bar_height, color=colors)\n",
    "\n",
    "# Add creators as labels\n",
    "for bar, creator in zip(bars, df[\"Created By\"]):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, creator,\n",
    "             ha='center', va='bottom', fontsize=9, rotation=90)\n",
    "\n",
    "# Remove y-axis ticks since height is symbolic\n",
    "plt.yticks([])\n",
    "plt.ylabel(\"Language Representation\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add title at the bottom\n",
    "plt.text(\n",
    "    0.5, -0.15, \"Popular Programming Languages and Their Creators\",\n",
    "    fontsize=14, fontweight='bold',\n",
    "    ha='center', transform=plt.gca().transAxes\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure properly to current directory\n",
    "file_name = \"popular_languages_creators_chart.png\"\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "plt.savefig(file_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved at:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41162305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    \"Language\": [\"Python\", \"Java\", \"R\", \"Javascript\", \"Swift\", \"C++\", \"C#\", \"PHP\", \"SQL\", \"Go\"],\n",
    "    \"Created By\": [\n",
    "        \"Guido van Rossum\", \"James Gosling\", \"Robert Gentleman, Ross Ihaka\", \"Netscape\",\n",
    "        \"Apple\", \"Bjarne Stroustrup\", \"Microsoft\", \"Rasmus Lerdorf\",\n",
    "        \"Donald D. Chamberlin, Raymond F. Boyce.\", \"Robert Griesemer, Ken Thompson, Rob Pike.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Placeholder bar height\n",
    "bar_height = np.ones(len(df)) * 1\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(df)))\n",
    "bars = plt.bar(df[\"Language\"], bar_height, color=colors)\n",
    "\n",
    "# Add creators as labels\n",
    "for bar, creator in zip(bars, df[\"Created By\"]):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, creator,\n",
    "             ha='center', va='bottom', fontsize=9, rotation=90)\n",
    "\n",
    "# Remove y-axis ticks since height is symbolic\n",
    "plt.yticks([])\n",
    "plt.ylabel(\"Language Representation\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add the title way below the chart\n",
    "plt.text(\n",
    "    0.5, -0.25,  # Very far down\n",
    "    \"Popular Programming Languages and Their Authors\",\n",
    "    fontsize=14, fontweight='bold',\n",
    "    ha='center', transform=plt.gca().transAxes\n",
    ")\n",
    "\n",
    "# Save with padding for title space\n",
    "#plt.savefig(file_path, dpi=300, bbox_inches='tight', pad_inches=1.0)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save chart in same directory\n",
    "file_name = \"popular_languages_creators_chart.png\"\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "plt.savefig(file_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Chart saved at:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a56aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the absolute file path of the notebook file\n",
    "file_path = os.path.abspath(\"Web-Scraping-Lab.ipynb\")\n",
    "print(\"The notebook is located at:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd7161e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa223cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbconvert\n",
    "import nbformat\n",
    "import pdfkit\n",
    "\n",
    "# Corrected file paths (Using raw string notation or forward slashes)\n",
    "input_file_path = r\"C:\\Users\\Ede\\Desktop\\IBM_Coursera_Data_Analyst_Projects\\CapStoneProjects\\module1\\Web-Scraping-Lab.ipynb\"\n",
    "output_pdf_path = r\"C:\\Users\\Ede\\Desktop\\IBM_Coursera_Data_Analyst_Projects\\CapStoneProjects\\module1\\Web-Scraping-Lab.pdf\"\n",
    "\n",
    "# Load the Jupyter Notebook file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Convert the notebook to HTML\n",
    "html_exporter = nbconvert.HTMLExporter()\n",
    "html_exporter.exclude_input = False  # Include code cells in the output\n",
    "(body, resources) = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Convert HTML to PDF\n",
    "pdfkit.from_string(body, output_pdf_path)\n",
    "\n",
    "# Return the PDF file path\n",
    "print(f\"Notebook successfully converted to PDF: {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af850576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98392ff",
   "metadata": {},
   "source": [
    "# Congratulations to us for having successfully completed the above lab!\n",
    "# Authors: \n",
    "<h4>Kelechukwu Innocent Ede and Ramesh Sannareddy</h4>\n",
    "\n",
    "# Other Contributors:\n",
    "<ul>\n",
    "<li>Rav Ahuja</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce3eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e14e499c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
